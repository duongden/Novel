#!/usr/bin/env python3
"""
ä¹¦æºæ¸…æ´—è„šæœ¬
- å»é™¤è¡¨æƒ…ç¬¦å·
- å»é™¤æ‹¬å·åŠå†…å®¹
- è½¬æ¢ç‰¹æ®Šå­—ç¬¦ï¼ˆåœ†åœˆæ•°å­—ã€å…¨è§’å­—ç¬¦ç­‰ï¼‰
- è§„èŒƒåç§°å’Œåˆ†ç»„
- æ¸…ç†å¤šä½™ç©ºæ ¼
- å¯é€‰ï¼šæŒ‰è¯„åˆ†è‡ªåŠ¨åˆ†ç»„ï¼ˆç²¾é€‰/æ ‡å‡†/å¤‡ç”¨ï¼‰+ æ’åº
"""

import json
import re
import time
import argparse
from pathlib import Path

# è¡¨æƒ…ç¬¦å·æ­£åˆ™ï¼ˆè¦†ç›–å¸¸è§ emoji èŒƒå›´ï¼‰
EMOJI_PATTERN = re.compile(
    "["
    "\U0001F300-\U0001F9FF"  # å¸¸è§ emoji
    "\U00002600-\U000027BF"  # æ‚é¡¹ç¬¦å·
    "\U0001FA00-\U0001FAFF"  # æ‰©å±•ç¬¦å·
    "\U00002300-\U000023FF"  # æŠ€æœ¯ç¬¦å·
    "\U00002B50-\U00002B55"  # æ˜Ÿæ˜Ÿç­‰
    "\U0000FE00-\U0000FE0F"  # å˜ä½“é€‰æ‹©å™¨
    "\U0000200D"             # é›¶å®½è¿æ¥ç¬¦
    "\U0001F1E0-\U0001F1FF"  # å›½æ——
    "]+",
    flags=re.UNICODE
)

# ç‰¹æ®Šç¬¦å·ï¼ˆéœ€è¦ç§»é™¤ï¼‰
SPECIAL_SYMBOLS = re.compile(
    r'[â˜…â˜†âœ¦âœ§â­ğŸŒŸğŸ’«ğŸ”¥ğŸ’¥âœ¨ğŸ‰ğŸŠğŸ“šğŸ“–ğŸ“•ğŸ“—ğŸ“˜ğŸ“™ğŸ‘ğŸ‘ğŸ‘ğŸ™ğŸ’ª'
    r'â¤ï¸ğŸ’•ğŸ’–ğŸ’—ğŸ’™ğŸ’šğŸ’›âœ…âŒâ­•â—â“'
    r'â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³'
    r'ã‰‘ã‰’ã‰“ã‰”ã‰•ã‰–ã‰—ã‰˜ã‰™ã‰šã‰›ã‰œã‰ã‰ã‰Ÿ'
    r'â°Â¹Â²Â³â´âµâ¶â·â¸â¹âºâ»'
    r'â… -â…«ï½~ä¸¨|ï½œğŸ‘ğŸ”°ğŸ¨ğŸ“»ğŸ“¥ğŸ’ '
    r'â—â–ªâ„¢ã€½ãŠ£â—â—‹â—†â—‡â– â–¡â–²â–³â–¼â–½'
    r'ï¼¡-ï¼ºï½-ï½šï¼-ï¼™'
    r']+'
)

# æ‹¬å·åŠå†…å®¹ï¼ˆä¸­æ–‡æ‹¬å·ã€è‹±æ–‡æ‹¬å·ã€æ–¹æ‹¬å·ã€å°–æ‹¬å·ï¼‰
BRACKET_PATTERN = re.compile(r'[ï¼ˆ(ã€\[<][^ï¼‰)ã€‘\]>]*[ï¼‰)ã€‘\]>]')

# åç§°åç¼€æ¸…æ´—æ¨¡å¼ï¼ˆæŒ‰é¡ºåºåº”ç”¨ï¼‰
NAME_SUFFIX_PATTERNS = [
    (r'^æºç¤¾åŒºå‡ºå“-', ''),                     # æ¥æºå‰ç¼€ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
    (r'^[+\-#.Â·]\s*', ''),                    # å¼€å¤´ç‰¹æ®Šç¬¦å·
    (r'#\d+$', ''),                           # #æ•°å­— ç‰ˆæœ¬å·
    (r'\s*#[^\s]+$', ''),                     # #ä½œè€…å ç½²å
    (r'\s+[^\s]+$', ''),                      # ç©ºæ ¼+å†…å®¹ï¼ˆå¦‚ "çˆ±ä¹¦åŒ… ç ´å†°"ï¼‰
    (r'_[a-zA-Z0-9.-]+\.[a-z]{2,}$', ''),    # _åŸŸå åç¼€
    (r'-[\u4e00-\u9fa5]{2,4}$', ''),          # -ä½œè€…å åç¼€
    (r'[a-z]\d{1,3}$', ''),                   # è‹±æ–‡+æ•°å­—åç¼€ï¼ˆå¦‚ b13ï¼‰
    (r'(?<=[^\d])\d{1,3}$', ''),              # çº¯æ•°å­—åç¼€
]

# åˆ†ç»„æ’åºé¡ºåº
GROUP_ORDER = {"ç²¾é€‰": 0, "æ ‡å‡†": 1, "å¤‡ç”¨": 2}

# åˆ†ç»„åç§°æ˜ å°„ï¼ˆåŸå§‹ -> æ ‡å‡†ï¼‰
GROUP_MAPPING = {
    "ğŸŒŸ æŠ“åŒ…": "æŠ“åŒ…",
    "ğŸ‰ ç²¾é€‰": "ç²¾é€‰",
    "ğŸ”° æ­£ç‰ˆ": "æ­£ç‰ˆ",
    "ğŸ’  ç»¼åˆ": "ç»¼åˆ",
    "ğŸ“¥ ä¸‹è½½": "ä¸‹è½½",
    "ğŸ“š å‡ºç‰ˆ": "å‡ºç‰ˆ",
    "ğŸ¨ æ¼«ç”»": "æ¼«ç”»",
    "ğŸ“» æœ‰å£°": "æœ‰å£°",
    "æŠ“åŒ…": "æŠ“åŒ…",
    "ç²¾é€‰": "ç²¾é€‰",
    "æ­£ç‰ˆ": "æ­£ç‰ˆ",
    "ç»¼åˆ": "ç»¼åˆ",
    "ä¸‹è½½": "ä¸‹è½½",
    "å‡ºç‰ˆ": "å‡ºç‰ˆ",
    "æ¼«ç”»": "æ¼«ç”»",
    "æœ‰å£°": "æœ‰å£°",
}


def calculate_quality_score(source: dict) -> int:
    """è®¡ç®—ä¹¦æºè´¨é‡è¯„åˆ†ï¼ˆæ»¡åˆ†çº¦ 60ï¼‰"""
    score = 0

    # åŸºç¡€çŠ¶æ€ (0-7)
    if source.get('enabled', True):
        score += 5
    if source.get('enabledExplore'):
        score += 2

    # å“åº”æ—¶é—´ (0-15)
    rt = source.get('respondTime', 99999)
    if rt < 1000:
        score += 15
    elif rt < 3000:
        score += 12
    elif rt < 5000:
        score += 8
    elif rt < 10000:
        score += 4

    # è§„åˆ™å®Œæ•´æ€§ (0-20)
    if source.get('searchUrl'):
        score += 4
    if source.get('ruleSearch') or source.get('searchRule'):
        score += 4
    if source.get('ruleToc') or source.get('tocRule'):
        score += 4
    if source.get('ruleContent') or source.get('contentRule'):
        score += 6
    if source.get('exploreUrl'):
        score += 2

    # æ›´æ–°æ—¶é—´ (0-10)
    last = source.get('lastUpdateTime', 0)
    if last:
        days = max(0, (time.time() * 1000 - last) / 86400000)
        if days < 30:
            score += 10
        elif days < 90:
            score += 7
        elif days < 180:
            score += 4
        elif days < 365:
            score += 2

    # æƒé‡ (0-5)
    score += min(source.get('weight', 0) // 100, 5)

    return score


def get_grade_group(score: int) -> str:
    """æ ¹æ®è¯„åˆ†è¿”å›åˆ†ç»„åç§°"""
    if score >= 45:
        return "ç²¾é€‰"
    elif score >= 40:
        return "æ ‡å‡†"
    else:
        return "å¤‡ç”¨"


def strip_decorations(text: str) -> str:
    """ç§»é™¤è£…é¥°æ€§å†…å®¹ï¼ˆè¡¨æƒ…ã€ç‰¹æ®Šç¬¦å·ã€æ‹¬å·ã€åç¼€ç­‰ï¼‰"""
    if not text:
        return ""
    text = EMOJI_PATTERN.sub("", text)
    text = SPECIAL_SYMBOLS.sub("", text)
    text = BRACKET_PATTERN.sub("", text)
    # åç§°åç¼€æ¸…æ´—
    for pattern, replacement in NAME_SUFFIX_PATTERNS:
        text = re.sub(pattern, replacement, text)
    return text


def clean_spaces(text: str) -> str:
    """æ¸…ç†ç©ºæ ¼"""
    if not text:
        return ""
    # å»é™¤é¦–å°¾ç©ºæ ¼
    text = text.strip()
    # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
    text = re.sub(r'\s+', ' ', text)
    return text


def normalize_group(group: str) -> str:
    """è§„èŒƒåŒ–åˆ†ç»„åç§°"""
    if not group:
        return ""

    # å…ˆå°è¯•ç›´æ¥æ˜ å°„
    if group in GROUP_MAPPING:
        return GROUP_MAPPING[group]

    # æ¸…æ´—åå†æ˜ å°„
    cleaned = clean_spaces(strip_decorations(group))
    if cleaned in GROUP_MAPPING:
        return GROUP_MAPPING[cleaned]

    return cleaned


def clean_source(source: dict, grade: bool = False) -> dict:
    """æ¸…æ´—å•ä¸ªä¹¦æº"""
    # æ¸…æ´—åç§°
    if "bookSourceName" in source:
        source["bookSourceName"] = clean_spaces(strip_decorations(source["bookSourceName"]))

    # æŒ‰è¯„åˆ†åˆ†ç»„ï¼ˆè¦†ç›–åŸæœ‰åˆ†ç»„ï¼‰
    if grade:
        score = calculate_quality_score(source)
        source["bookSourceGroup"] = get_grade_group(score)
    # ä»…æ¸…æ´—åˆ†ç»„
    elif "bookSourceGroup" in source:
        source["bookSourceGroup"] = normalize_group(source["bookSourceGroup"])

    # æ¸…æ´—å¤‡æ³¨ï¼ˆä¿ç•™å†…å®¹ï¼Œåªå»è¡¨æƒ…ï¼‰
    if "bookSourceComment" in source and source["bookSourceComment"]:
        # å¤‡æ³¨å¯èƒ½åŒ…å«ä½¿ç”¨è¯´æ˜ï¼Œåªå»é™¤å¼€å¤´çš„è¡¨æƒ…
        comment = source["bookSourceComment"]
        # åªæ¸…ç†å¼€å¤´çš„è¡¨æƒ…ç¬¦å·
        comment = re.sub(r'^[\s]*' + EMOJI_PATTERN.pattern, '', comment)
        source["bookSourceComment"] = comment.strip()

    return source


def clean_sources(sources: list, grade: bool = False) -> list:
    """æ‰¹é‡æ¸…æ´—ä¹¦æº"""
    return [clean_source(s, grade) for s in sources]


def sort_sources(sources: list) -> list:
    """æŒ‰åˆ†ç»„å’Œåç§°æ’åº"""
    return sorted(sources, key=lambda s: (
        GROUP_ORDER.get(s.get("bookSourceGroup", ""), 99),
        s.get("bookSourceName", "")
    ))


def main():
    parser = argparse.ArgumentParser(description="ä¹¦æºæ¸…æ´—è„šæœ¬")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--grade", "-g", action="store_true", help="æŒ‰è¯„åˆ†è‡ªåŠ¨åˆ†ç»„ï¼ˆç²¾é€‰/æ ‡å‡†/å¤‡ç”¨ï¼‰+ æ’åº")
    args = parser.parse_args()

    input_path = Path(args.input)
    output_path = Path(args.output)

    if not input_path.exists():
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ {input_path}")
        return 1

    # è¯»å–ä¹¦æº
    with open(input_path, "r", encoding="utf-8") as f:
        sources = json.load(f)

    print(f"è¯»å–ä¹¦æºï¼š{len(sources)} ä¸ª")
    if args.grade:
        print("å¯ç”¨è¯„åˆ†åˆ†ç»„ + æ’åºæ¨¡å¼")

    # æ¸…æ´—
    cleaned = clean_sources(sources, grade=args.grade)

    # æ’åºï¼ˆä»…åœ¨ grade æ¨¡å¼ä¸‹ï¼‰
    if args.grade:
        cleaned = sort_sources(cleaned)

    # è¾“å‡º
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(cleaned, f, ensure_ascii=False, indent=2)

    print(f"æ¸…æ´—å®Œæˆï¼Œè¾“å‡ºåˆ°ï¼š{output_path}")

    # ç»Ÿè®¡
    groups = {}
    for s in cleaned:
        g = s.get("bookSourceGroup", "æœªåˆ†ç»„")
        groups[g] = groups.get(g, 0) + 1

    print("\nåˆ†ç»„ç»Ÿè®¡ï¼š")
    for g, count in sorted(groups.items(), key=lambda x: GROUP_ORDER.get(x[0], 99)):
        print(f"  {g or 'æœªåˆ†ç»„'}: {count}")

    return 0


if __name__ == "__main__":
    exit(main())
